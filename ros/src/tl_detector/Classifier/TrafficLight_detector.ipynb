{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hagen\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten, Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detected_traffic_lights(boxes, scores, classes):\n",
    "    \"\"\"\n",
    "    filter traffic lights from detected objects\n",
    "    \n",
    "    Args:\n",
    "        boxes (np): coordinates of objects in image\n",
    "        scores (np): confidence factor for detected objects\n",
    "        classes (np): class for each object\n",
    "    Returns:\n",
    "        filtered_boxes (np): coordinates of traffic lights in image\n",
    "        filtered_scores (np): confidence factors for detected traffic lights\n",
    "    \"\"\"\n",
    "    \n",
    "    #get all detected traffic lights with a score above 0.1\n",
    "    inds = ((classes == 10) & (scores >= 0.1)).nonzero()\n",
    "    \n",
    "    filtered_boxes = boxes[inds[0], ...]\n",
    "    filtered_scores = scores[inds[0], ...]\n",
    "    return filtered_boxes, filtered_scores\n",
    "        \n",
    "def crop_detection(image, boxes, path, img):\n",
    "    \"\"\"\n",
    "    cut traffic lights for image and save them to folder given by path\n",
    "    \n",
    "    Args:\n",
    "        image : image containing detected objects\n",
    "        boxes (np): coordinates of objects in image\n",
    "        path (str): path for saving traffic lights\n",
    "        img (str): path + name of image\n",
    "    \"\"\"\n",
    "    height = image.shape[1]\n",
    "    width = image.shape[2]\n",
    "        \n",
    "    # Box coordinates are scaled and need to be converted\n",
    "    # into image coordinates\n",
    "    boxes[:, 0] *= height\n",
    "    boxes[:, 1] *= width\n",
    "    boxes[:, 2] *= height\n",
    "    boxes[:, 3] *= width\n",
    "        \n",
    "    # cropping needs integers \n",
    "    boxes = boxes.astype(int)\n",
    "        \n",
    "    name = img.split('\\\\')[1]\n",
    "    name = name.split('.')[0]\n",
    "        \n",
    "    # loop over every detected traffic light\n",
    "    for i in range(len(boxes)):\n",
    "        bot, left, top, right = boxes[i,...]\n",
    "\n",
    "        cropped = image[0,bot:top,left:right]\n",
    "            \n",
    "        # only needed for testing\n",
    "        save_img = cv2.cvtColor(cropped, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(path+'/'+name+'_'+str(i)+'_cropped.jpg',save_img)\n",
    "        #plt.imshow(cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph functions\n",
    "\n",
    "Frozen graph of [SSD MobileNet](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) pretrained on COCO provided by [Tensorflow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_SSD_MobileNet(path_frozen_model):\n",
    "    \"\"\"\n",
    "    load frozen graph\n",
    "    \n",
    "    Args:\n",
    "        path_frozen_model (str): path to frozen graph\n",
    "    Returns:\n",
    "        graph\n",
    "        image_tensor: input tensor for graph\n",
    "        detection_boxes: output tensor for coordinates of detected objects\n",
    "        detection_scores: output tensor for confidence factor of detected objects\n",
    "        detection_classes: output tensor for detected classes\n",
    "    \"\"\"\n",
    "    #loads a frozen SSD MobileNet\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        od_graph_def = tf.GraphDef()\n",
    "        with tf.gfile.GFile(path_frozen_model, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            od_graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(od_graph_def, name='')\n",
    "            \n",
    "        # get Tensors for input image + boxes for detected objects + classification for each box\n",
    "        # + scores for how certain the classifier is\n",
    "        image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
    "        detection_boxes = graph.get_tensor_by_name('detection_boxes:0')\n",
    "        detection_classes = graph.get_tensor_by_name('detection_classes:0')\n",
    "        detection_scores = graph.get_tensor_by_name('detection_scores:0')       \n",
    "    return graph, image_tensor, detection_boxes,detection_scores,detection_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects_in_single_img(detection_graph, image_tensor, detection_boxes,\\\n",
    "                                detection_scores, detection_classes, image):\n",
    "    \"\"\"\n",
    "    use loaded and pretrained graph for object detection\n",
    "    \n",
    "    Args:\n",
    "        detection_graph\n",
    "        image_tensor: input tensor for graph\n",
    "        detection_boxes: output tensor for coordinates of detected objects\n",
    "        detection_scores: output tensor for confidence factor of detected objects\n",
    "        detection_classes: output tensor for detected classes\n",
    "    Returns:\n",
    "        boxes (np): coordinates of objects in image\n",
    "        scores (np): confidence factor for detected objects\n",
    "        classes (np): class for each object\n",
    "    \"\"\"\n",
    "  \n",
    "    with tf.Session(graph=detection_graph) as sess:                  \n",
    "        (boxes, scores, classes) = sess.run([detection_boxes, detection_scores, detection_classes], \n",
    "                                            feed_dict={image_tensor: image})\n",
    "\n",
    "        # Remove unnecessary dimensions\n",
    "        boxes = np.squeeze(boxes)\n",
    "        scores = np.squeeze(scores)\n",
    "        classes = np.squeeze(classes)\n",
    "\n",
    "        return boxes, scores, classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run graph and detect objects in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen_model='frozen_inference_graph.pb' #path to frozen model\n",
    "test_images= glob.glob('images_for_detection/*.jpg') #get path to images\n",
    "path_cropped_images = 'images_for_detection/cropped' #path for saving the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load frozen model\n",
    "detection_graph,image_tensor,detection_boxes,detection_scores,detection_classes = load_SSD_MobileNet(frozen_model)\n",
    "for img in test_images: \n",
    "    image = cv2.imread(img) #read image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #convert to RGB\n",
    "    image = np.expand_dims(image, 0) #extra dim needed by graph\n",
    "    boxes,scores,classes = detect_objects_in_single_img(detection_graph, image_tensor, detection_boxes,\\\n",
    "                                                        detection_scores, detection_classes, image)\n",
    "    #get images of traffic lights\n",
    "    boxes, scores = get_detected_traffic_lights(boxes, scores, classes)\n",
    "    crop_detection(image, boxes,path_cropped_images, img) #save images of traffic lights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
